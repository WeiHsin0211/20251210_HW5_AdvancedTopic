import streamlit as st
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import re
import docx
import pandas as pd
import altair as alt
import os
import PyPDF2
# ==========================================
# 1. è¨­å®šèˆ‡é¢¨æ ¼
# ==========================================
st.set_page_config(page_title="AI Content Detector", page_icon="ğŸ¤–", layout="wide")

st.markdown("""
<style>
    .block-container { padding-top: 1rem !important; padding-bottom: 2rem !important; }
    .stApp {
        background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
        background-size: 400% 400%;
        animation: gradient 15s ease infinite;
        color: #ffffff;
    }
    @keyframes gradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    h1, h2, h3, p { text-align: center; }
    .stTextArea>div>div>textarea {
        background-color: rgba(255, 255, 255, 0.95) !important;
        color: #1a1a1a !important;
        border-radius: 12px;
        font-size: 1.1rem;
    }
    .stFileUploader {
        padding: 15px;
        background: rgba(255, 255, 255, 0.2);
        border-radius: 12px;
        backdrop-filter: blur(5px);
    }
    .stButton>button {
        background: white !important;
        color: #e73c7e !important;
        border-radius: 25px;
        font-size: 1.2rem;
        font-weight: bold;
        border: none;
        padding: 0.5rem 2rem;
        transition: transform 0.2s;
        display: block;
        margin: 10px auto;
    }
    .stButton>button:hover { transform: scale(1.05); }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. æ¨¡å‹è¼‰å…¥é‚è¼¯ (ç´”æ·¨ç‰ˆ)
# ==========================================

@st.cache_resource
def get_model_resource(model_name):
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name)
        model.eval()
        return tokenizer, model
    except Exception:
        return None, None

def compute_perplexity(text: str, tokenizer, model) -> float:
    if not text.strip(): return 0.0
    try:
        inputs = tokenizer(text, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs, labels=inputs["input_ids"])
            loss = outputs.loss
        return float(torch.exp(loss).item())
    except:
        return 0.0

def map_perplexity_to_ai_probability(ppl: float) -> int:
    ppl_clamped = max(5.0, min(100.0, ppl))
    ai_prob = 100 - (ppl_clamped - 5) * (90 / 95)
    return max(5, min(95, int(round(ai_prob))))

def get_highlighted_text(text: str, tokenizer, model) -> tuple[str, float]:
    #sentences = re.split(r'(?<=[.!?ã€‚ï¼ï¼Ÿ])\s*', text)
    split_pattern = r'(?:(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+)|(?:\n+)'
    sentences = re.split(split_pattern, text)
    sentences = [s for s in sentences if s.strip()]
    if not sentences: return "", 0.0
    
    highlighted_parts = []
    total_ai_prob = 0
    valid_count = 0
    
    for sentence in sentences:
        # ğŸ‘‡ ä¿®æ­£é‡é»ï¼šå³ä½¿æ˜¯çŸ­å­— (æ¨™é»ç¬¦è™Ÿ)ï¼Œä¹Ÿè¦çµ¦å®ƒé¡è‰²ï¼Œé¿å…è¦–è¦ºæ–·è£‚
        if len(sentence) < 2:
            # çŸ­å­—å…ƒç›´æ¥è¦–ç‚ºä¸Šä¸€å¥çš„å±¬æ€§ï¼Œæˆ–çµ¦äºˆä¸­æ€§ç¶ è‰²
            hl = f'<span style="background-color: transparent; color: black; padding: 2px 4px; border-radius: 4px; margin: 0 2px;">{sentence}</span>'
            highlighted_parts.append(hl)
            continue
        ppl = compute_perplexity(sentence, tokenizer, model)
        ai_prob = map_perplexity_to_ai_probability(ppl)
        total_ai_prob += ai_prob
        valid_count += 1
        
        # é¡è‰²æ¨™è¨˜é‚è¼¯
        if ai_prob > 80:
            hl = f'<span style="background-color: #fee2e2; color: #991b1b; padding: 2px 4px; border-radius: 4px; margin: 0 2px;">{sentence}</span>'
        elif ai_prob > 60:
            hl = f'<span style="background-color: #fef3c7; color: #92400e; padding: 2px 4px; border-radius: 4px; margin: 0 2px;">{sentence}</span>'
        else:
            hl = f'<span style="background-color: #dcfce7; color: #166534; padding: 2px 4px; border-radius: 4px; margin: 0 2px; opacity: 0.8;">{sentence}</span>'
        highlighted_parts.append(hl)
        
    avg_prob = total_ai_prob / valid_count if valid_count > 0 else 0
    return "".join(highlighted_parts), avg_prob

# ==========================================
# 3. UI ä»‹é¢
# ==========================================

st.markdown("<h1 style='font-size: 3.5rem; text-shadow: 0 4px 10px rgba(0,0,0,0.2);'>AI Content Detector</h1>", unsafe_allow_html=True)
st.markdown("<p style='font-size: 1.2rem; opacity: 0.9; margin-bottom: 20px; text-shadow: 0 2px 4px rgba(0,0,0,0.2);'>è²¼ä¸Šæ–‡å­—æˆ–ä¸Šå‚³æª”æ¡ˆï¼Œè®“ AI å¹«ä½ è¾¨è­˜å…§å®¹æ˜¯å¦ç”±æ©Ÿå™¨ç”Ÿæˆï¼</p>", unsafe_allow_html=True)

if "user_text" not in st.session_state:
    st.session_state["user_text"] = ""

def on_file_upload():
    uploaded = st.session_state.uploaded_file_key
    if uploaded is not None:
        try:
            filename = uploaded.name.lower()
            text = ""
            if filename.endswith(".docx"):
                doc = docx.Document(uploaded)
                text = "\n".join([para.text for para in doc.paragraphs])
            elif filename.endswith(".pdf"):
                reader = PyPDF2.PdfReader(uploaded)
                for page in reader.pages:
                    text += page.extract_text() or ""
            else:
                text = uploaded.read().decode("utf-8")
            st.session_state["user_text"] = text
        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {e}")

c1, c2, c3 = st.columns([1, 6, 1]) 

with c2:
    # st.markdown("""
    # <div style="background-color: rgba(255, 255, 255, 0.2); backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.3); border-radius: 20px; padding: 15px 25px; margin-bottom: 25px; box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);">
    #     <h3 style="margin: 0 0 10px 0; color: white; font-size: 1.2rem;">âš™ï¸ æ ¸å¿ƒè¨­å®š (Settings)</h3>
    # </div>
    # """, unsafe_allow_html=True)

    col_opt, col_info = st.columns([3, 1])
    
    with col_opt:
        language_option = st.selectbox(
            "é¸æ“‡èªè¨€æ¨¡å‹ / Select Model",
            ["Traditional Chinese (ä¸­æ–‡)", "English (è‹±æ–‡)"],
            index=0
        )
    
    if "Chinese" in language_option:
        # è‡ªå‹•åµæ¸¬æœ¬åœ°è³‡æ–™å¤¾
        if os.path.exists("./model_cn"):
            TARGET_MODEL = "./model_cn"
            status_label = "ğŸŸ¢ ä¸­æ–‡æ ¸å¿ƒ (Local)"
        else:
            TARGET_MODEL = "uer/gpt2-chinese-cluecorpussmall"
            status_label = "ğŸŸ  ä¸­æ–‡æ ¸å¿ƒ (Online)"
    else:
        TARGET_MODEL = "gpt2"
        status_label = "ğŸ”µ English Core"

    with col_info:
        st.markdown(f"""<div style="margin-top: 28px; background: rgba(0,0,0,0.2); color: white; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold; font-size: 0.8rem;">{status_label}</div>""", unsafe_allow_html=True)

    # è¼‰å…¥æ¨¡å‹
    with st.spinner(f"æ­£åœ¨è¼‰å…¥ {status_label}..."):
        tokenizer, model = get_model_resource(TARGET_MODEL)
    
    # éŒ¯èª¤è™•ç†
    if tokenizer is None or model is None:
        if "Chinese" in language_option:
            st.warning("âš ï¸ ä¸­æ–‡æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œåˆ‡æ›è‡³å‚™æ´æ¨¡å‹ (gpt2)ã€‚")
            with st.spinner("åˆ‡æ›ä¸­..."):
                tokenizer, model = get_model_resource("gpt2")
        else:
            st.error("âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹ã€‚")
            st.stop()

    st.markdown("---")
    st.file_uploader("Upload File (TXT, PDF, DOCX)", type=['txt', 'pdf', 'docx'], key="uploaded_file_key", on_change=on_file_upload)
    
    text_input = st.text_area("Paste text here", value=st.session_state["user_text"], height=250)
    final_text = text_input # å®šç¾© final_text è®Šæ•¸
    
    st.write("")
    detect_button = st.button("ğŸ” Start Analysis")

# ==========================================
# 4. åˆ†æçµæœ (çµ•å°ä¿®å¾©ç‰ˆï¼šPython é ç®—é¡è‰²)
# ==========================================
if detect_button:
    # è™•ç†è®Šæ•¸å¯èƒ½æœªå®šç¾©çš„æƒ…æ³
    if 'final_text' not in locals() or not final_text.strip():
        st.warning("âš ï¸ è«‹è¼¸å…¥å…§å®¹æˆ–ä¸Šå‚³æª”æ¡ˆ")
    else:
        with c2:
            with st.spinner("Analyzing content..."):
                # ---------------------------------------------------------
                # 1. è¨ˆç®—é‚è¼¯
                # ---------------------------------------------------------
                hl_html, avg_prob = get_highlighted_text(final_text, tokenizer, model)
                
                #sentences = re.split(r'(?<=[.!?ã€‚ï¼ï¼Ÿ])\s*', final_text)
                # âœ… ä¿®æ”¹å¾Œçš„å¯«æ³• (å¿…é ˆè·Ÿä¸Šé¢å‡½å¼ä¸€æ¨¡ä¸€æ¨£)
                split_pattern = r'(?:(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+)|(?:\n+)'
                sentences_list = re.split(split_pattern, final_text)
                lens = [len(s.strip()) for s in sentences_list if len(s.strip()) > 1]
                
                chart_data = []
                for i, s in enumerate(sentences_list):
                    if len(s.strip()) > 1:
                        p = compute_perplexity(s, tokenizer, model)
                        prob = map_perplexity_to_ai_probability(p)
                        
                        short_s = s[:15] + "..." if len(s) > 15 else s
                        
                        # ğŸ‘‡ğŸ‘‡ğŸ‘‡ ä¿®æ­£é‡é» 1ï¼šç›´æ¥åœ¨ Python è£¡æ±ºå®šé¡è‰²ï¼Œé¿é–‹ Altair éŒ¯èª¤ ğŸ‘‡ğŸ‘‡ğŸ‘‡
                        if prob > 80:
                            bar_color = '#e73c7e'  # ç´… (High AI)
                        elif prob > 60:
                            bar_color = '#f59e0b'  # é»ƒ (Medium)
                        else:
                            bar_color = '#23d5ab'  # ç¶  (Human)

                        chart_data.append({
                            "SentenceID": f"å¥ {i+1}", 
                            "Probability": int(prob), 
                            "Text": s,
                            "Summary": short_s,
                            "BarColor": bar_color  # æŠŠé¡è‰²å­˜é€²å»
                        })

                if lens:
                    df_len = pd.DataFrame(lens, columns=['len'])
                    burstiness = df_len['len'].std() / df_len['len'].mean() if df_len['len'].mean() > 0 else 0
                else:
                    burstiness = 0

                # ---------------------------------------------------------
                # 2. é¡¯ç¤º UIï¼šåˆ†æ•¸å¡ç‰‡
                # ---------------------------------------------------------
                st.markdown(f"""
<div style="background-color: white; color: black; padding: 30px; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-bottom: 25px;">
<div style="display: flex; justify-content: space-around; align-items: center;">
<div style="flex: 1; border-right: 1px solid #eee; display: flex; flex-direction: column; align-items: center;">
<h3 style="margin: 0; color: #666; font-size: 1rem;">AI Probability</h3>
<h1 style="margin: 5px 0; font-size: 3.5em; color: {'#e73c7e' if avg_prob > 50 else '#23d5ab'};">{avg_prob:.0f}%</h1>
<p style="font-size: 0.9rem; color: #888; margin: 0;">åˆ¤æ–·çµæœ</p>
</div>
<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
<h3 style="margin: 0; color: #666; font-size: 1rem;">Burstiness Score</h3>
<h1 style="margin: 5px 0; font-size: 3.5em; color: #333;">{burstiness:.2f}</h1>
<p style="font-size: 0.9rem; color: #888; margin: 0;">å¥å­ç¯€å¥è®ŠåŒ–</p>
</div>
</div>
<div style="text-align: center; margin-top: 10px;">
<p style="color: #444; font-weight: bold; margin: 0;">{'é€™æ®µæ–‡å­—çœ‹èµ·ä¾†å¾ˆåƒ AI å¯«çš„' if avg_prob > 50 else 'é€™æ®µæ–‡å­—çœ‹èµ·ä¾†å¾ˆè‡ªç„¶ (Human-written)'}</p>
</div>
</div>
""", unsafe_allow_html=True)

                # ---------------------------------------------------------
                # 3. é¡¯ç¤º UIï¼šè©³ç´°åˆ†æå ±å‘Š
                # ---------------------------------------------------------
                st.markdown("### ğŸ“ è©³ç´°åˆ†æå ±å‘Š")
                st.markdown(f"""
<div style="background-color: white; color: #333; padding: 25px; border-radius: 10px; line-height: 2.0; font-size: 1.05rem; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
{hl_html}
</div>
""", unsafe_allow_html=True)
                st.caption("ğŸ”´ ç´…è‰²ï¼šæ¥µé«˜ AI å«Œç–‘ (>80%) | ğŸŸ¡ é»ƒè‰²ï¼šç–‘ä¼¼ AI (60-80%) | ğŸŸ¢ ç¶ è‰²ï¼šäººé¡é¢¨æ ¼ (<60%)")

                # ---------------------------------------------------------
                # 4. åœ–è¡¨ (é€™è£¡æ”¹äº†ï¼ç›´æ¥è®€å– BarColor)
                # ---------------------------------------------------------
                if chart_data:
                    df_chart = pd.DataFrame(chart_data)
                    dynamic_h = max(300, len(chart_data) * 40)
                    
                    c = alt.Chart(df_chart).mark_bar(
                        cornerRadiusTopRight=10,
                        cornerRadiusBottomRight=10
                    ).encode(
                        x=alt.X('Probability', title='AI å¯èƒ½æ€§ (%)', scale=alt.Scale(domain=[0, 100])),
                        y=alt.Y('SentenceID', sort=None, title='å¥å­ç´¢å¼•'),
                        # ğŸ‘‡ğŸ‘‡ğŸ‘‡ ä¿®æ­£é‡é» 2ï¼šé€™è£¡ç›´æ¥ä½¿ç”¨æˆ‘å€‘ç®—å¥½çš„ BarColor æ¬„ä½ï¼Œä¸åšåˆ¤æ–· ğŸ‘‡ğŸ‘‡ğŸ‘‡
                        color=alt.Color('BarColor', scale=None), 
                        tooltip=['SentenceID', 'Probability', 'Text']
                    ).properties(
                        height=dynamic_h,
                        background='#ffffff'
                    ).configure_axis(
                        labelColor='#333', 
                        titleColor='#333', 
                        grid=False
                    ).configure_view(
                        strokeWidth=0
                    )

                    st.markdown("""<div style="background-color: transparent; border-radius: 12px; padding: 10px; ; margin-top: 20px;"><h4 style="text-align: center; color: white margin: 0 0 15px 0;">ğŸ“Š å¥å­è©³ç´°æ•¸æ“šå¯è¦–åŒ–</h4>""", unsafe_allow_html=True)
                    st.altair_chart(c, use_container_width=True)
                    st.markdown("</div>", unsafe_allow_html=True)